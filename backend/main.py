from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from apscheduler.schedulers.background import BackgroundScheduler
from contextlib import asynccontextmanager
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.database import init_db, save_job, get_all_jobs, get_job_count_by_platform
from backend.crawlers.saramin import SaraminCrawler
from backend.crawlers.jobkorea import JobKoreaCrawler
from backend.crawlers.linkedin import LinkedInCrawler

scheduler = BackgroundScheduler(timezone="Asia/Seoul")


def crawl_all_jobs():
    print("\n" + "=" * 50)
    print("ğŸ”„ ì±„ìš©ê³µê³  í¬ë¡¤ë§ ì‹œì‘...")
    print("=" * 50)

    new_jobs_count = 0

    try:
        saramin = SaraminCrawler()
        for job in saramin.fetch_backend_jobs(count=50):
            if save_job(job):
                new_jobs_count += 1
    except Exception as e:
        print(f"âŒ ì‚¬ëŒì¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    try:
        jobkorea = JobKoreaCrawler()
        for job in jobkorea.fetch_backend_jobs(max_jobs=30):
            if save_job(job):
                new_jobs_count += 1
    except Exception as e:
        print(f"âŒ ì¡ì½”ë¦¬ì•„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    try:
        linkedin = LinkedInCrawler()
        for job in linkedin.fetch_backend_jobs(max_jobs=20):
            if save_job(job):
                new_jobs_count += 1
    except Exception as e:
        print(f"âŒ LinkedIn í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ìƒˆë¡œìš´ ê³µê³  {new_jobs_count}ê°œ ì¶”ê°€ë¨")
    return new_jobs_count


@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘...")
    init_db()
    crawl_all_jobs()
    scheduler.add_job(crawl_all_jobs, 'interval', hours=1, id='crawl_job')
    scheduler.start()
    yield
    scheduler.shutdown()


app = FastAPI(title="ë°±ì—”ë“œ ì±„ìš©ê³µê³  API", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/")
def read_root():
    return {"message": "ë°±ì—”ë“œ ì±„ìš©ê³µê³  API ì„œë²„ì…ë‹ˆë‹¤."}


@app.get("/api/jobs")
def list_jobs(platform: str = Query(None), limit: int = Query(100)):
    jobs = get_all_jobs(platform=platform, limit=limit)
    return {"total": len(jobs), "jobs": jobs}


@app.post("/api/crawl")
def trigger_crawl():
    new_count = crawl_all_jobs()
    return {"message": "í¬ë¡¤ë§ ì™„ë£Œ", "new_jobs_added": new_count}


@app.get("/api/stats")
def get_stats():
    platform_counts = get_job_count_by_platform()
    total = sum(platform_counts.values())
    return {"total_jobs": total, "by_platform": platform_counts}
